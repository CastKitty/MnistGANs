{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"DCGANMnist.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"metadata":{"id":"pxL5Fet3sAdV","colab_type":"code","outputId":"9c5963ce-0cc2-4878-9f24-ed9b75a804f8","colab":{"base_uri":"https://localhost:8080/","height":496},"executionInfo":{"status":"ok","timestamp":1539996849294,"user_tz":300,"elapsed":45481,"user":{"displayName":"Erik The Red","photoUrl":"","userId":"17101191086331650576"}}},"cell_type":"code","source":["import tensorflow as tf\n","import keras \n","import matplotlib.pyplot as plt\n","import numpy as np\n","from tensorflow.examples.tutorials.mnist import input_data\n","mnist = input_data.read_data_sets('MNIST_data')\n","tf.reset_default_graph()\n","batch_size = 64\n","n_noise = 64\n","\n","X_in = tf.placeholder(dtype=tf.float32, shape=[None, 28, 28], name='X')\n","noise = tf.placeholder(dtype=tf.float32, shape=[None, n_noise])\n","\n","keep_prob = tf.placeholder(dtype=tf.float32, name='keep_prob')\n","is_training = tf.placeholder(dtype=tf.bool, name='is_training')\n","\n","def lrelu(x):\n","    return tf.maximum(x, tf.multiply(x, 0.2))\n","\n","def binary_cross_entropy(x, z):\n","    eps = 1e-12\n","    return (-(x * tf.log(z + eps) + (1. - x) * tf.log(1. - z + eps)))\n","  \n","def discriminator(img_in, reuse=None, keep_prob=keep_prob):\n","    activation = lrelu\n","    with tf.variable_scope(\"discriminator\", reuse=reuse):\n","        x = tf.reshape(img_in, shape=[-1, 28, 28, 1])\n","        x = tf.layers.conv2d(x, kernel_size=5, filters=64, strides=2, padding='same', activation=activation)\n","        x = tf.layers.dropout(x, keep_prob)\n","        x = tf.layers.conv2d(x, kernel_size=5, filters=64, strides=1, padding='same', activation=activation)\n","        x = tf.layers.dropout(x, keep_prob)\n","        x = tf.layers.conv2d(x, kernel_size=5, filters=64, strides=1, padding='same', activation=activation)\n","        x = tf.layers.dropout(x, keep_prob)\n","        x = tf.contrib.layers.flatten(x)\n","        x = tf.layers.dense(x, units=128, activation=activation)\n","        x = tf.layers.dense(x, units=1, activation=tf.nn.sigmoid)\n","        return x\n","      \n","      \n","def generator(z, keep_prob=keep_prob, is_training=is_training):\n","    activation = lrelu\n","    momentum = 0.99\n","    with tf.variable_scope(\"generator\", reuse=None):\n","        x = z\n","        d1 = 4\n","        d2 = 1\n","        x = tf.layers.dense(x, units=d1 * d1 * d2, activation=activation)\n","        x = tf.layers.dropout(x, keep_prob)      \n","        x = tf.contrib.layers.batch_norm(x, is_training=is_training, decay=momentum)  \n","        x = tf.reshape(x, shape=[-1, d1, d1, d2])\n","        x = tf.image.resize_images(x, size=[7, 7])\n","        x = tf.layers.conv2d_transpose(x, kernel_size=5, filters=64, strides=2, padding='same', activation=activation)\n","        x = tf.layers.dropout(x, keep_prob)\n","        x = tf.contrib.layers.batch_norm(x, is_training=is_training, decay=momentum)\n","        x = tf.layers.conv2d_transpose(x, kernel_size=5, filters=64, strides=2, padding='same', activation=activation)\n","        x = tf.layers.dropout(x, keep_prob)\n","        x = tf.contrib.layers.batch_norm(x, is_training=is_training, decay=momentum)\n","        x = tf.layers.conv2d_transpose(x, kernel_size=5, filters=64, strides=1, padding='same', activation=activation)\n","        x = tf.layers.dropout(x, keep_prob)\n","        x = tf.contrib.layers.batch_norm(x, is_training=is_training, decay=momentum)\n","        x = tf.layers.conv2d_transpose(x, kernel_size=5, filters=1, strides=1, padding='same', activation=tf.nn.sigmoid)\n","        return x\n","      \n","g = generator(noise, keep_prob, is_training)\n","d_real = discriminator(X_in)\n","d_fake = discriminator(g, reuse=True)\n","\n","vars_g = [var for var in tf.trainable_variables() if var.name.startswith(\"generator\")]\n","vars_d = [var for var in tf.trainable_variables() if var.name.startswith(\"discriminator\")]\n","\n","\n","d_reg = tf.contrib.layers.apply_regularization(tf.contrib.layers.l2_regularizer(1e-6), vars_d)\n","g_reg = tf.contrib.layers.apply_regularization(tf.contrib.layers.l2_regularizer(1e-6), vars_g)\n","\n","loss_d_real = binary_cross_entropy(tf.ones_like(d_real), d_real)\n","loss_d_fake = binary_cross_entropy(tf.zeros_like(d_fake), d_fake)\n","loss_g = tf.reduce_mean(binary_cross_entropy(tf.ones_like(d_fake), d_fake))\n","loss_d = tf.reduce_mean(0.5 * (loss_d_real + loss_d_fake))\n","\n","update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n","with tf.control_dependencies(update_ops):\n","    optimizer_d = tf.train.RMSPropOptimizer(learning_rate=0.00015).minimize(loss_d + d_reg, var_list=vars_d)\n","    optimizer_g = tf.train.RMSPropOptimizer(learning_rate=0.00015).minimize(loss_g + g_reg, var_list=vars_g)\n","    \n","    \n","sess = tf.Session()\n","sess.run(tf.global_variables_initializer())\n","\n","\n","for i in range(6):\n","    train_d = True\n","    train_g = True\n","    keep_prob_train = 0.6 # 0.5\n","    \n","    \n","    n = np.random.uniform(0.0, 1.0, [batch_size, n_noise]).astype(np.float32)   \n","    batch = [np.reshape(b, [28, 28]) for b in mnist.train.next_batch(batch_size=batch_size)[0]]  \n","    \n","    d_real_ls, d_fake_ls, g_ls, d_ls = sess.run([loss_d_real, loss_d_fake, loss_g, loss_d], feed_dict={X_in: batch, noise: n, keep_prob: keep_prob_train, is_training:True})\n","    \n","    d_real_ls = np.mean(d_real_ls)\n","    d_fake_ls = np.mean(d_fake_ls)\n","    g_ls = g_ls\n","    d_ls = d_ls\n","    \n","    if g_ls * 1.5 < d_ls:\n","        train_g = False\n","        pass\n","    if d_ls * 2 < g_ls:\n","        train_d = False\n","        pass\n","    \n","    if train_d:\n","        sess.run(optimizer_d, feed_dict={noise: n, X_in: batch, keep_prob: keep_prob_train, is_training:True})\n","        \n","        \n","    if train_g:\n","        sess.run(optimizer_g, feed_dict={noise: n, keep_prob: keep_prob_train, is_training:True})"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From <ipython-input-1-d3d351b349be>:6: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please write your own downloading logic.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use urllib or similar directly.\n","Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use tf.data to implement this functionality.\n","Extracting MNIST_data/train-images-idx3-ubyte.gz\n","Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use tf.data to implement this functionality.\n","Extracting MNIST_data/train-labels-idx1-ubyte.gz\n","Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n","Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n","Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n","Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"],"name":"stdout"}]},{"metadata":{"id":"7NC3lvVkCMQP","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}